image: fare-docker-reg.dock.studios:5000/python:3.10

# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  MYSQL_DATABASE: terrareg-integration
  MYSQL_ROOT_PASSWORD: password

# Pip's cache doesn't store the python packages
# https://pip.pypa.io/en/stable/reference/pip_install/#caching
#
# If you want to also cache the installed packages, you have to install
# them in a virtualenv and cache it as well.
cache:
  paths:
    - .cache/pip
    - venv/
    - terraform-docs

.before_script_python:
  before_script:
    # Install terraform-docs
    - test -f ./terraform-docs || { wget https://github.com/terraform-docs/terraform-docs/releases/download/v0.16.0/terraform-docs-v0.16.0-linux-amd64.tar.gz && tar -zxvf terraform-docs-v0.16.0-linux-amd64.tar.gz && chmod +x terraform-docs && rm terraform-docs-v0.16.0-linux-amd64.tar.gz; }
    - cp terraform-docs /usr/local/bin/
    - python --version  # For debugging
    - pip install --proxy=$http_proxy virtualenv
    - virtualenv venv
    - source venv/bin/activate
    - pip install --proxy=$http_proxy -r requirements.txt

unit-tests:
  stage: test
  extends: .before_script_python
  script:
    - pip install --proxy=$http_proxy -r requirements-dev.txt
    - coverage run -m pytest --verbose ./test/unit
    - coverage report
    - coverage xml
  artifacts:
    reports:
      cobertura: coverage.xml

integration-tests:
  stage: test
  extends: .before_script_python
  script:
    - pip install --proxy=$http_proxy -r requirements-dev.txt
    - coverage run -m pytest --verbose ./test/integration
    - coverage report
    - coverage xml
  artifacts:
    reports:
      cobertura: coverage.xml

mysql-integration-tests:
  stage: test
  extends: .before_script_python
  services:
    - name: fare-docker-reg.dock.studios:5000/mysql:8.0.29
      alias: mysql
  variables:
    # Set database url for integration tests
    INTEGRATION_DATABASE_URL: mysql+mysqlconnector://root:${MYSQL_ROOT_PASSWORD}@mysql/${MYSQL_DATABASE}
    # Set datbase URL for schema migration
    DATABASE_URL: mysql+mysqlconnector://root:${MYSQL_ROOT_PASSWORD}@mysql/${MYSQL_DATABASE}
  script:
    - pip install --proxy=$http_proxy -r requirements-dev.txt
    # Perform database migration
    - alembic upgrade head
    # Run integration tests
    - coverage run -m pytest --verbose ./test/integration
    - coverage report
    - coverage xml
  artifacts:
    reports:
      cobertura: coverage.xml

build-wheel:
  stage: build
  extends: .before_script_python
  script:
    - python setup.py bdist_wheel
    # an alternative approach is to install and run:
    - pip install --proxy=$http_proxy dist/*
    # run the command here
  artifacts:
    paths:
      - dist/*.whl

release:
  stage: deploy
  image: fare-docker-reg.dock.studios:5000/semantic-release:latest
  cache:
    paths:
      - node_modules/
  variables:
    GITLAB_TOKEN: $GITLAB_TOKEN
  script:
    - semantic-release
  only:
    - main

